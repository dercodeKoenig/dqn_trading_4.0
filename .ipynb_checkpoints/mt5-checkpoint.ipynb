{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af5e31c2-459a-4e27-9741-349c1d31f586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AccountInfo(login=150475, trade_mode=0, leverage=50, limit_orders=0, margin_so_mode=0, trade_allowed=True, trade_expert=True, margin_mode=2, currency_digits=2, fifo_close=False, balance=1000.0, credit=0.0, profit=0.0, equity=1000.0, margin=0.0, margin_free=1000.0, margin_level=0.0, margin_so_call=100.0, margin_so_so=70.0, margin_initial=0.0, margin_maintenance=0.0, assets=0.0, liabilities=0.0, commission_blocked=0.0, name='Marvin Eckhardt', server='Osprey-Demo', currency='USD', company='Osprey Ltd'),\n",
       " ())"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd    \n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import ta\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "seq_len = 24*4*2\n",
    "\n",
    "account = int(150475)\n",
    "mt5.initialize()\n",
    "authorized=mt5.login(account)\n",
    "mt5.account_info(), mt5.positions_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aead5b10-a961-42cb-99ca-1805fb3319eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 192, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 192, 6)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 192, 32)      608         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 192, 32)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 192, 38)      0           reshape[0][0]                    \n",
      "                                                                 leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 192, 64)      2496        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 192, 64)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 192, 64)      4160        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 192, 64)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "positions (Positions)           (None, 192, 64)      0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (None, 192, 64)      108096      positions[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_1 (Transforme (None, 192, 64)      108096      transformer_block[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 128)          74496       transformer_block_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 130)          0           input_2[0][0]                    \n",
      "                                                                 gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          16768       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 128)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          16512       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          16512       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 128)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 3)            384         leaky_re_lu_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 348,128\n",
      "Trainable params: 348,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2493e7ad358>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    embed_dim = 0\n",
    "    num_heads = 0\n",
    "    ff_dim = 0 \n",
    "    rate=0\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "\n",
    "\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update()\n",
    "        cfg.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'ff_dim': self.ff_dim,\n",
    "            'rate': self.rate,\n",
    "        })\n",
    "        return cfg  \n",
    "    def call(self, inputs, training = False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    \n",
    "def getPositionEncoding(seq_len, d, n=10000):\n",
    "    P = np.zeros((seq_len, d))\n",
    "    for k in range(seq_len):\n",
    "        for i in np.arange(int(d/2)):\n",
    "            denominator = np.power(n, 2*i/d)\n",
    "            P[k, 2*i] = np.sin(k/denominator)\n",
    "            P[k, 2*i+1] = np.cos(k/denominator)\n",
    "    return P[::]\n",
    "\n",
    "class Positions(tf.keras.layers.Layer):\n",
    "    P = []\n",
    "    d = 0\n",
    "    seq_len = 0\n",
    "    def __init__(self, seq_len, d, **kwargs):\n",
    "        super(Positions, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.d = d\n",
    "        self.p = getPositionEncoding(seq_len, d)\n",
    "        \n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.p\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update()\n",
    "        cfg.update({\n",
    "            'p': self.p,\n",
    "            'seq_len': self.seq_len,\n",
    "            'd': self.d\n",
    "        })\n",
    "        return cfg  \n",
    "    \n",
    "    \n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs_1 = tf.keras.layers.Input(shape = (seq_len, 6))\n",
    "inputs_pos = tf.keras.layers.Input(shape = (2))\n",
    "\n",
    "x = tf.keras.layers.Reshape((seq_len,6))(inputs_1)\n",
    "\n",
    "x2 = tf.keras.layers.Conv1D(32,3, padding=\"same\")(x)\n",
    "x2 = tf.keras.layers.LeakyReLU(alpha=0.1)(x2)\n",
    "x = tf.keras.layers.Concatenate()([x,x2])\n",
    "\n",
    "x = tf.keras.layers.Dense(64)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(64)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "x = Positions(seq_len, x.shape[-1])(x)\n",
    "x = TransformerBlock(x.shape[2], 6, 64)(x)\n",
    "x = TransformerBlock(x.shape[2], 6, 64)(x)\n",
    "\n",
    "#x = tf.keras.layers.LSTM(128, activation = \"tanh\", return_sequences = True)(x)\n",
    "x = tf.keras.layers.GRU(128, activation = \"tanh\", return_sequences = False)(x)\n",
    "#x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "#x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Concatenate()([inputs_pos, x])\n",
    "\n",
    "x = tf.keras.layers.Dense(128)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(128)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(128)(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "outputs = tf.keras.layers.Dense(3, activation = \"linear\", use_bias=False)(x)\n",
    "model = tf.keras.Model([inputs_1,inputs_pos], outputs)\n",
    "model.summary()\n",
    "\n",
    "model.load_weights(\"relearn6.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bec95b78-c79a-4461-bd87-14cc8befae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class candle_class:\n",
    "  pass\n",
    "    \n",
    "class manager:\n",
    "    candles = []\n",
    "    def __init__(self, model):\n",
    "        self.candles = []\n",
    "        self.model = model\n",
    "        self.position = 0\n",
    "        self.current_win = 0\n",
    "        self.win = 0\n",
    "        self.last_balance = 0\n",
    "        \n",
    "        self.order_value_constant = 1000\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    def candles_to_dataframe(self, candles):\n",
    "        o = [x.o for x in candles]\n",
    "        h = [x.h for x in candles]\n",
    "        l = [x.l for x in candles]\n",
    "        c = [x.c for x in candles]\n",
    "        data = {\"Open\":o, \"High\":h, \"Low\":l, \"Close\":c}\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    \n",
    "    def add_new_candle(self, t,o,h,l,c):\n",
    "            \n",
    "        new_candle = candle_class()\n",
    "        new_candle.t = t\n",
    "        new_candle.o = o\n",
    "        new_candle.h = h\n",
    "        new_candle.l = l\n",
    "        new_candle.c = c\n",
    "        self.candles.append(new_candle)\n",
    "        \n",
    "        if len(self.candles) >= 200:\n",
    "            \n",
    "            df = self.candles_to_dataframe(self.candles[-21:])\n",
    "            sma21_raw = list(ta.trend.SMAIndicator(df[\"Close\"], 21).sma_indicator())[-1]\n",
    "            \n",
    "            #df = self.candles_to_dataframe(self.candles[-50:])\n",
    "            #sma50_raw = list(ta.trend.SMAIndicator(df[\"Close\"], 50).sma_indicator())[-1]\n",
    "            \n",
    "            df = self.candles_to_dataframe(self.candles[-200:])\n",
    "            sma200_raw = list(ta.trend.SMAIndicator(df[\"Close\"], 200).sma_indicator())[-1]\n",
    "            \n",
    "            df = self.candles_to_dataframe(self.candles[-14:])\n",
    "            rsi_14 = list(ta.momentum.RSIIndicator(df[\"Close\"], 14).rsi())[-1] / 50 - 1\n",
    "\n",
    "            df = self.candles_to_dataframe(self.candles[-200:])\n",
    "            atr_value = list(ta.volatility.AverageTrueRange(df[\"High\"], df[\"Low\"], df[\"Close\"], 200).average_true_range())[-1]\n",
    "        \n",
    "            #df = self.candles_to_dataframe(self.candles[-21:])\n",
    "            #donchi = ta.volatility.DonchianChannel(df[\"High\"], df[\"Low\"], df[\"Close\"], 21)\n",
    "            #dh = list(donchi.donchian_channel_hband())[-1]\n",
    "            #dl = list(donchi.donchian_channel_lband())[-1]\n",
    "            \n",
    "            #new_candle.dh = dh\n",
    "            #new_candle.dl = dl\n",
    "            new_candle.sma21 = sma21_raw\n",
    "            #new_candle.sma50 = sma50_raw\n",
    "            new_candle.sma200 = sma200_raw\n",
    "            new_candle.rsi14 = rsi_14\n",
    "            new_candle.atr_value = atr_value\n",
    "            \n",
    "            self.candles[-1] = new_candle\n",
    "            \n",
    "        if len(self.candles) > seq_len + 200:\n",
    "            del self.candles[0]\n",
    "            \n",
    "        \n",
    "        if self.position != 0:\n",
    "          current_price = self.candles[-1].c\n",
    "          entry = self.entry_price\n",
    "          diff = (current_price - entry) / entry * self.order_value_constant\n",
    "\n",
    "          if self.position == 1:\n",
    "            self.current_win = diff\n",
    "          if self.position == -1:\n",
    "            self.current_win = -diff\n",
    "            \n",
    "          \n",
    "        \n",
    "    def sample_to_x_y(self, sample):\n",
    "        \n",
    "                current_close = sample[-1].c\n",
    "\n",
    "                prev_close = [candle.c for candle in sample]\n",
    "                prev_high = [candle.h for candle in sample]\n",
    "                prev_low = [candle.l for candle in sample]\n",
    "\n",
    "                prev_sma21 = [candle.sma21 for candle in sample]\n",
    "                #prev_sma50 = [candle.sma50 for candle in sample]\n",
    "                prev_sma200 = [candle.sma200 for candle in sample]\n",
    "                \n",
    "                #dl = [candle.dl for candle in sample]\n",
    "                #dh = [candle.dh for candle in sample]\n",
    "\n",
    "                #dl_relative = [-(current_close - dl[o]) / dl[o] for o in range(seq_len)]\n",
    "                #dh_relative = [-(current_close - dh[o]) / dh[o] for o in range(seq_len)]\n",
    "                \n",
    "                prev_sma21_relative = [-(current_close - prev_sma21[o]) / prev_sma21[o] for o in range(seq_len)]\n",
    "                #prev_sma50_relative = [-(current_close - prev_sma50[o]) / prev_sma50[o] for o in range(seq_len)]\n",
    "                prev_sma200_relative = [-(current_close - prev_sma200[o]) / prev_sma200[o] for o in range(seq_len)]\n",
    "\n",
    "                prev_close_relative = [-(current_close - prev_close[o]) / prev_close[o] for o in range(seq_len)]\n",
    "                prev_high_relative = [-(current_close - prev_high[o]) / prev_high[o] for o in range(seq_len)]\n",
    "                prev_low_relative = [-(current_close - prev_low[o]) / prev_low[o] for o in range(seq_len)]\n",
    "\n",
    "                maxval = max(prev_high_relative)\n",
    "                minval = min(prev_low_relative)\n",
    "                #scale = 1 / (maxval - minval)\n",
    "                scale = 1 / (sample[-1].atr_value / sample[-1].c) # / (maxval - minval)\n",
    "\n",
    "                prev_sma21_relative_scaled = [i * scale for i in prev_sma21_relative]\n",
    "                #prev_sma50_relative_scaled = [i * scale for i in prev_sma50_relative]\n",
    "                prev_sma200_relative_scaled = [i * scale for i in prev_sma200_relative]\n",
    "\n",
    "                prev_close_relative_scaled = [i * scale for i in prev_close_relative]\n",
    "                prev_low_relative_scaled = [i * scale for i in prev_low_relative]\n",
    "                prev_high_relative_scaled = [i * scale for i in prev_high_relative]\n",
    "\n",
    "                #dl_rel_scaled = [i * scale for i in dl_relative]\n",
    "                #dh_rel_scaled = [i * scale for i in dh_relative]\n",
    "                \n",
    "                prev_rsi_14 = [candle.rsi14 for candle in sample]\n",
    "                \n",
    "\n",
    "                x = []\n",
    "                for o in range(len(prev_close)):\n",
    "                    ts = []\n",
    "\n",
    "                    ts.append(prev_close_relative_scaled[o])\n",
    "                    ts.append(prev_high_relative_scaled[o])\n",
    "                    ts.append(prev_low_relative_scaled[o])\n",
    "\n",
    "                    ts.append(prev_sma21_relative_scaled[o])\n",
    "                    #ts.append(prev_sma50_relative_scaled[o])\n",
    "                    ts.append(prev_sma200_relative_scaled[o])\n",
    "                    \n",
    "                    #ts.append(dh_rel_scaled[o])\n",
    "                    #ts.append(dl_rel_scaled[o])\n",
    "                    \n",
    "                    ts.append(prev_rsi_14[o])\n",
    "\n",
    "                    x.append(ts)\n",
    "\n",
    "                x = np.array(x)\n",
    "                return x\n",
    "        \n",
    "        \n",
    "    def get_current_inference_data(self):\n",
    "        if len(self.candles) == seq_len + 200:\n",
    "            sample = self.candles[-seq_len:]\n",
    "            inference_data = self.sample_to_x_y(sample)\n",
    "            return inference_data\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    \n",
    "  \n",
    "    def close(self):\n",
    "        self.position = 0\n",
    "        self.win += self.current_win\n",
    "        self.current_win = 0\n",
    "      \n",
    "    def entry(self,price):\n",
    "        self.entry_price = price\n",
    "        self.win -= comission * self.order_value_constant\n",
    "\n",
    "        \n",
    "    def evaluate(self):\n",
    "        d = x.get_current_inference_data()\n",
    "        if type(d) == type(None):\n",
    "            return None, None, None\n",
    "        nm = self.model.predict([d.reshape(1,seq_len,6), np.array([self.position, self.current_win]).reshape(1,2)])[0]\n",
    "        action = np.argmax(nm)\n",
    "        price = self.candles[-1].c\n",
    "        \n",
    "        if action == 0:\n",
    "            if self.position != 0:\n",
    "                self.close()\n",
    "            pass\n",
    "    \n",
    "        if action == 1:\n",
    "          #short\n",
    "            if self.position == 1:\n",
    "                self.close()\n",
    "\n",
    "            if self.position == -1:\n",
    "                pass\n",
    "            else:\n",
    "                self.position = -1\n",
    "                self.entry(price)\n",
    "        \n",
    "        if action == 2:\n",
    "            #long\n",
    "            if self.position == -1:\n",
    "                self.close()\n",
    "\n",
    "            if self.position == 1:\n",
    "                pass\n",
    "            else:\n",
    "                self.position = 1\n",
    "                self.entry(price)\n",
    "                \n",
    "        balance = self.win + self.current_win\n",
    "        change = balance - self.last_balance\n",
    "        self.last_balance = balance\n",
    "        \n",
    "\n",
    "\n",
    "        return nm, change, balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ec590cd-d000-43a1-8843-df58a7a0b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class candle_class:\n",
    "    pass\n",
    "\n",
    "def sample_to_x_y(sample):\n",
    "        \n",
    "                current_close = sample[-1].c\n",
    "\n",
    "                prev_close = [candle.c for candle in sample]\n",
    "                prev_high = [candle.h for candle in sample]\n",
    "                prev_low = [candle.l for candle in sample]\n",
    "\n",
    "                prev_sma21 = [candle.sma21 for candle in sample]\n",
    "                #prev_sma50 = [candle.sma50 for candle in sample]\n",
    "                prev_sma200 = [candle.sma200 for candle in sample]\n",
    "                \n",
    "                #dl = [candle.dl for candle in sample]\n",
    "                #dh = [candle.dh for candle in sample]\n",
    "\n",
    "                #dl_relative = [-(current_close - dl[o]) / dl[o] for o in range(seq_len)]\n",
    "                #dh_relative = [-(current_close - dh[o]) / dh[o] for o in range(seq_len)]\n",
    "                \n",
    "                prev_sma21_relative = [-(current_close - prev_sma21[o]) / prev_sma21[o] for o in range(seq_len)]\n",
    "                #prev_sma50_relative = [-(current_close - prev_sma50[o]) / prev_sma50[o] for o in range(seq_len)]\n",
    "                prev_sma200_relative = [-(current_close - prev_sma200[o]) / prev_sma200[o] for o in range(seq_len)]\n",
    "\n",
    "                prev_close_relative = [-(current_close - prev_close[o]) / prev_close[o] for o in range(seq_len)]\n",
    "                prev_high_relative = [-(current_close - prev_high[o]) / prev_high[o] for o in range(seq_len)]\n",
    "                prev_low_relative = [-(current_close - prev_low[o]) / prev_low[o] for o in range(seq_len)]\n",
    "\n",
    "                maxval = max(prev_high_relative)\n",
    "                minval = min(prev_low_relative)\n",
    "                #scale = 1 / (maxval - minval)\n",
    "                scale = 1 / (sample[-1].atr_value / sample[-1].c) # / (maxval - minval)\n",
    "\n",
    "                prev_sma21_relative_scaled = [i * scale for i in prev_sma21_relative]\n",
    "                #prev_sma50_relative_scaled = [i * scale for i in prev_sma50_relative]\n",
    "                prev_sma200_relative_scaled = [i * scale for i in prev_sma200_relative]\n",
    "\n",
    "                prev_close_relative_scaled = [i * scale for i in prev_close_relative]\n",
    "                prev_low_relative_scaled = [i * scale for i in prev_low_relative]\n",
    "                prev_high_relative_scaled = [i * scale for i in prev_high_relative]\n",
    "\n",
    "                #dl_rel_scaled = [i * scale for i in dl_relative]\n",
    "                #dh_rel_scaled = [i * scale for i in dh_relative]\n",
    "                \n",
    "                prev_rsi_14 = [candle.rsi14 for candle in sample]\n",
    "                \n",
    "\n",
    "                x = []\n",
    "                for o in range(len(prev_close)):\n",
    "                    ts = []\n",
    "\n",
    "                    ts.append(prev_close_relative_scaled[o])\n",
    "                    ts.append(prev_high_relative_scaled[o])\n",
    "                    ts.append(prev_low_relative_scaled[o])\n",
    "\n",
    "                    ts.append(prev_sma21_relative_scaled[o])\n",
    "                    #ts.append(prev_sma50_relative_scaled[o])\n",
    "                    ts.append(prev_sma200_relative_scaled[o])\n",
    "                    \n",
    "                    #ts.append(dh_rel_scaled[o])\n",
    "                    #ts.append(dl_rel_scaled[o])\n",
    "                    \n",
    "                    ts.append(prev_rsi_14[o])\n",
    "\n",
    "                    x.append(ts)\n",
    "\n",
    "                x = np.array(x)\n",
    "                return x\n",
    "\n",
    "class mt5_manager:\n",
    "    def __init__(self, symbol):\n",
    "        self.symbol = symbol\n",
    "        \n",
    "    def update(self):\n",
    "        t = int(time.time()) + 60*60*24\n",
    "        \n",
    "        prices = mt5.copy_rates_from(self.symbol, mt5.TIMEFRAME_M15, t, seq_len+200)\n",
    "      \n",
    "        o = [x[1] for x in prices]\n",
    "        h = [x[2] for x in prices]\n",
    "        l = [x[3] for x in prices]\n",
    "        c = [x[4] for x in prices]\n",
    "        \n",
    "        data = {\"Time\": [x[0] for x in prices], \"Open\":o, \"High\":h, \"Low\":l, \"Close\":c}\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        \n",
    "        \n",
    "        sma21_raw = list(ta.trend.SMAIndicator(df[\"Close\"], 21).sma_indicator())\n",
    "        sma200_raw = list(ta.trend.SMAIndicator(df[\"Close\"], 200).sma_indicator())\n",
    "        rsi_14 = [i / 50 - 1 for i in list(ta.momentum.RSIIndicator(df[\"Close\"], 14).rsi())]\n",
    "        atr_value = list(ta.volatility.AverageTrueRange(df[\"High\"], df[\"Low\"], df[\"Close\"], 200).average_true_range())\n",
    "        \n",
    "        candles = []\n",
    "        for i in range(200,200+seq_len):\n",
    "            new_candle = candle_class()\n",
    "            \n",
    "            new_candle.sma21 = sma21_raw[i]\n",
    "            new_candle.sma200 = sma200_raw[i]\n",
    "            new_candle.rsi14 = rsi_14[i]\n",
    "            new_candle.atr_value = atr_value[i]\n",
    "            _, o, h, l, c = df.iloc[i]\n",
    "            new_candle.o = o\n",
    "            new_candle.h = h\n",
    "            new_candle.l = l\n",
    "            new_candle.c = c\n",
    "            \n",
    "            candles.append(new_candle)\n",
    "            \n",
    "        sample = sample_to_x_y(candles)\n",
    "        \n",
    "        positions = mt5.positions_get(symbol=self.symbol)\n",
    "        return sample, positions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10a1bfef-c1b6-4a08-b75b-c66d3de8705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eurusd_manager = mt5_manager(\"EURUSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b28bb4d9-b2ff-4330-b72f-e411f9890ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eurusd_manager.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2892806-b008-496e-9c89-d5e905f8a6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
